#+title: Portland Unemployment 2007 to 2017

This notebook looks at the unemployment rate for the Portland-Hillsboro-Vancouver area (in Oregon and Washington State) from January 2007 through February 2017. I want to answer the questions - /How has Portland's unemployment rate changed over the last ten years and how does it compare to the national unemployment rate?/ Additionally, I'd like to see how well this metric follows the /S&P 500 Index/ and the /Housing Price Index/.

* The Tangle
#+BEGIN_SRC python :tangle common.py
<<imports>>

<<constants>>

<<download-data>>
#+END_SRC

#+RESULTS:

* Imports and Setup
#+BEGIN_SRC ipython :session nationaldata :results none :noweb-ref imports
# python standard library
import os

# third-party
import matplotlib.pyplot as pyplot
import numpy
import pandas
import seaborn
#+END_SRC

#+BEGIN_SRC ipython :session nationaldata :results none
% matplotlib inline
#+END_SRC

* Data
** Dropbox
*** National Unemployment: https://www.dropbox.com/s/qw2l5hmu061l8x2/national_unemployment.csv?dl=0
*** Portland Hillsboro Vancouver: https://www.dropbox.com/s/wvux3d7dcaae5t0/portland_unemployment_2007_2017.csv?dl=0
*** Purchase Only House Price:
    https://www.dropbox.com/s/4hu2jpjkhcnr35k/purchase_only_house_price_index.csv?dl=0
*** S&P 500 Index
    https://www.dropbox.com/s/ojj5zp7feid6wwl/SP500_index.csv?dl=0
** Constants
#+BEGIN_SRC ipython :session nationaldata :results none :noweb-ref constants
class Urls(object):
    national = "https://www.dropbox.com/s/qw2l5hmu061l8x2/national_unemployment.csv?dl=1"
    portland = "https://www.dropbox.com/s/wvux3d7dcaae5t0/portland_unemployment_2007_2017.csv?dl=1"
    house_price = "https://www.dropbox.com/s/4hu2jpjkhcnr35k/purchase_only_house_price_index.csv?dl=1"
    s_and_p = "https://www.dropbox.com/s/ojj5zp7feid6wwl/SP500_index.csv?dl=1"
#+END_SRC

#+BEGIN_SRC ipython :session nationaldata :results none
class Paths(object):
    portland = "portland_unemployment_2007_2017.csv"
    national = "national_unemployment.csv"
    s_and_p = "SP500_index.csv"
    house_price = "purchase_only_house_price_index.csv"
#+END_SRC

** Downloading
#+BEGIN_SRC ipython :session nationaldata :results none :noweb-ref download-data
def download_data(path, url):
    """downloads the file if it doesn't exist
    Args:
     path (str): path to the file
     url (str): download url
    returns: DataFrame created from the file
    """
    if not os.path.isfile(path):
        response = requests.get(url)
        with open(path, 'w') as writer:
            writer.write(response.text)
    return pandas.read_csv(path)
#+END_SRC

* Portland
   The data represents  `Local Area Unemployment Statistics` for the *Portland-Hillsboro-Vancouver* area in Oregon and was taken from the [[https://data.bls.gov/cgi-bin/surveymost?la+41][Bureau of Labor Statistics]] (the /Portland-Vancouver-Hillsboro, OR-WA Metropolitan Statistical Area/).  It has monthly values starting from January 2007 and continues through February 2017.

 https://beta.bls.gov/dataViewer/view/timeseries/LAUMT413890000000003


   | Item                    | Value                                                                               |
   |-------------------------+-------------------------------------------------------------------------------------|
   | Data extracted on       | April 25, 2017 (3:13:28 PM)                                                         |
   | Series Id               | LAUMT413890000000003,LAUMT413890000000004,LAUMT413890000000005,LAUMT413890000000006 |
   | Not Seasonally Adjusted |                                                                                     |
   | Area                    | Portland-Vancouver-Hillsboro, OR-WA Metropolitan Statistical Area                   |
   | Area Type               | Metropolitan areas                                                                  |
   | State/Region/Division   | Oregon                                                                              |

 Data extracted on: Apr 30, 2017 (6:54:00 PM)

 Local Area Unemployment Statistics

 Series Title	:	Unemployment Rate: Portland-Vancouver-Hillsboro, OR-WA Metropolitan Statistical Area (U)
 Series ID	:	LAUMT413890000000003
 Seasonality	:	Not Seasonally Adjusted
 Survey Name	:	Local Area Unemployment Statistics
 Measure Data Type	:	unemployment rate
 Area	:	Portland-Vancouver-Hillsboro, OR-WA Metropolitan Statistical Area
 Area Type	:	Metropolitan areas

 #+BEGIN_SRC ipython :session nationaldata :results none
portland = download_data(Paths.portland, Urls.portland)
 #+END_SRC

 #+BEGIN_SRC ipython :session nationaldata
portland.describe()
 #+END_SRC

 #+RESULTS:
 :               Year       Value
 : count   122.000000  122.000000
 : mean   2011.590164    7.181967
 : std       2.945101    2.203154
 : min    2007.000000    3.900000
 : 25%    2009.000000    5.300000
 : 50%    2012.000000    6.750000
 : 75%    2014.000000    8.875000
 : max    2017.000000   11.400000

 #+BEGIN_SRC ipython :session nationaldata
portland.head()
 #+END_SRC

 #+RESULTS:
 :               Series ID  Year Period     Label  Value
 : 0  LAUMT413890000000003  2007    M01  2007 Jan    5.4
 : 1  LAUMT413890000000003  2007    M02  2007 Feb    5.5
 : 2  LAUMT413890000000003  2007    M03  2007 Mar    5.3
 : 3  LAUMT413890000000003  2007    M04  2007 Apr    5.0
 : 4  LAUMT413890000000003  2007    M05  2007 May    4.7

*** Cleaning

    I changed to a slightly different data-source so that I could get direct links to the data, so I'm going  to re-name some of the columns to match what I was using befroe

 #+BEGIN_SRC ipython :session nationaldata
column_renames = {"Value": "unemployment_rate",
                  "Label": "date"}
portland.rename(columns=column_renames,
                inplace=True)
portland.columns
 #+END_SRC

    #+RESULTS:
    : Index(['Series ID', 'Year', 'Period', 'date', 'unemployment_rate'], dtype='object')
   
    Now I'll re-do the dates.

 #+BEGIN_SRC ipython :session nationaldata
portland.Period.unique()
 #+END_SRC

 #+RESULTS:
 : array(['M01', 'M02', 'M03', 'M04', 'M05', 'M06', 'M07', 'M08', 'M09',
 :        'M10', 'M11', 'M12'], dtype=object)

 I use the months in one of the plots as labels so I'm going to create a column with just their (abbreviated) names.

 #+BEGIN_SRC ipython :session nationaldata
month_map = dict(M01="Jan", M02="Feb", M03="Mar", M04="Apr", M05="May",
                 M06="Jun", M07="Jul", M08="Aug", M09="Sep", M10="Oct",
                 M11="Nov", M12="Dec")
portland["month"] = portland.Period.apply(lambda x: month_map[x])
portland.head()
 #+END_SRC

    #+RESULTS:
    :               Series ID  Year Period      date  unemployment_rate month
    : 0  LAUMT413890000000003  2007    M01  2007 Jan                5.4   Jan
    : 1  LAUMT413890000000003  2007    M02  2007 Feb                5.5   Feb
    : 2  LAUMT413890000000003  2007    M03  2007 Mar                5.3   Mar
    : 3  LAUMT413890000000003  2007    M04  2007 Apr                5.0   Apr
    : 4  LAUMT413890000000003  2007    M05  2007 May                4.7   May

 In the plot I'm going to mark where the unemployment was at its highest point.

 #+BEGIN_SRC ipython :session nationaldata :results output
highest_unemployment = portland.unemployment_rate.max()
print(highest_unemployment)
unemployment_peaks = numpy.where(portland.unemployment_rate==highest_unemployment)[0]
 #+END_SRC   

 #+RESULTS:
 : 11.4

 #+BEGIN_SRC ipython :session nationaldata
unemployment_peaks
 #+END_SRC

 #+RESULTS:
 : array([29, 36])

 #+BEGIN_SRC ipython :session nationaldata :results output
print(portland.date.ix[unemployment_peaks[0]])
print(portland.date.ix[unemployment_peaks[1]])
 #+END_SRC

 #+RESULTS:
 : 2009 Jun
 : 2010 Jan

 It looks like it reached 11.4% twice - on June, 2009 and January of 2010.

 #+BEGIN_SRC ipython :session nationaldata :results output
lowest_unemployment = portland.unemployment_rate.min()
print(lowest_unemployment)
print(highest_unemployment/lowest_unemployment)
print(str(portland.date.ix[numpy.where(
    portland.unemployment_rate==lowest_unemployment)]))
 #+END_SRC

 #+RESULTS:
 : 3.9
 : 2.92307692308
 : 121    2017 Feb
 : Name: date, dtype: object

 At its peak, the unemployment rate for the Portland-Hillsboro-Vancouver area was almost three times higher than the most recent (preliminary) unemployment rate.

According to the [[https://www.nber.org/cycles.html][National Bureau of Economic Research]], the most recent economic contraction occurred from December 2007 through June 2009 which falls within the data set so I'll highlight that on the plot.

#+BEGIN_SRC ipython :session nationaldata :results output
recession_start = numpy.where(portland.date=="2007 Dec")[0][0]
recession_end = numpy.where(portland.date=="2009 Jun")[0][0]
portland_recession_start = portland.unemployment_rate.iloc[recession_start]
print(portland_recession_start)
print(portland.unemployment_rate.iloc[recession_end])
#+END_SRC

#+RESULTS:
: 4.8
: 11.4

When did it reach the recession-start rate?

#+BEGIN_SRC ipython :session nationaldata
portland.date.iloc[numpy.where(portland.unemployment_rate==portland_recession_start)[0][1]]
#+END_SRC

#+RESULTS:
: 2015 Oct

*** Unemployment Rate Over Time

    First I'll plot how the unemployment rate changed over time.

 #+BEGIN_SRC ipython :session nationaldata :file /tmp/unemployment_over_time.png
figure = pyplot.figure(figsize=(10, 10))
axe = figure.gca()
seaborn.set_style("whitegrid")
portland.plot(x="date", y="unemployment_rate", ax=axe, legend=False)
axe.set_title("Portland-Hillsboro-Vancouver Unemployment Over Time")
axe.set_ylabel("% Unemployed")
axe.set_xlabel("Month")
seaborn.despine()
 #+END_SRC

 #+RESULTS:
 [[file:/tmp/unemployment_over_time.png]]
 It looks like unemployment was relatively low until September of 2008, when it suddenly spiked before beginning a steady downward trend.

*** One Year

    There seems to be a lot of ups and downs in the plot. This next one will look at just the most recent years-worth of data.

 #+BEGIN_SRC ipython :session nationaldata :results none
year_2017 = portland[portland.Year > 2015]
year_2017 = year_2017[year_2017.date != "2016 Jan"]
 #+END_SRC

 #+BEGIN_SRC ipython :session nationaldata :file /tmp/unemployment_year.png
figure = pyplot.figure(figsize=(10, 10))
axe = figure.gca()
year_2017.plot(x="date", y="unemployment_rate", ax=axe, legend=False)
axe.set_title("Portland-Hillsboro-Vancouver Unemployment Rate Most Recent Year")
axe.set_xlabel("Month")
seaborn.despine()
 #+END_SRC

    #+RESULTS:
    [[file:/tmp/unemployment_year.png]]
 It seems like it had a spike during the Summer for some reason, but continued to decline overall.

*** By year
    I thought I'd separate out the years and see if the Summer spike happened during other years.
 #+BEGIN_SRC ipython :session nationaldata :file /tmp/unemployment_years.png
figure = pyplot.figure(figsize=(10,10))
axe = figure.gca()
years = portland[portland.Year < 2017]

for year in years.Year.unique():
    this_year = portland[portland.Year == year]
    this_year.plot(x="month", y="unemployment_rate", ax=axe,
                                     legend=False)
    axe.text(12, this_year.unemployment_rate.iloc[-1],
             "{0} (median: {1:.1f})".format(year, this_year.unemployment_rate.median()))
seaborn.despine()
source = portland[portland.Year == 2016]
axe.set_ylabel("% Unemployment")
axe.set_xlabel("Month")
axe.set_title("Portland-Hillsboro-Vancouver Unemployment Rate by Month")
 #+END_SRC

 #+RESULTS:
 [[file:/tmp/unemployment_years.png]]
 There does seem to be an upturn in the unemployment rate every May which then comes down in September. According to [[https://www.bls.gov/cps/seasfaq.htm][this FAQ]] from the Bureau of Labor Statistics, weather, school schedules, major holidays, and harvests are all regular occurences that affect the unemployment rate.

 #+BEGIN_SRC ipython :session nationaldata :file /tmp/course_4/median_unemployment_rates.png
figure = pyplot.figure(figsize=(10, 10))
axe = figure.gca()
years = portland[portland.Year < 2017]

medians = [portland[portland.Year==year].unemployment_rate.median()
           for year in years.Year.unique()]
axe.set_title("Portland-Hillsboro-Vancouver Median Unemployment Rate Per Year")
axe.plot(years.Year.unique(), medians)
seaborn.despine()
 #+END_SRC

 #+RESULTS:
 [[file:/tmp/course_4/median_unemployment_rates.png]]

 Looking at just the medians for each year shows a fairly steady decline after that initial spike.
   
* National
  As a comparison, I downloaded the unemployment rate data for the nation as a whole (also taken from the [[https://data.bls.gov/cgi-bin/surveymost?ln][Bureau of Labor Statistics]] - the =Unemployment Rate - LNS14000000= button.

https://beta.bls.gov/dataViewer/view/timeseries/LNU04000000

#+BEGIN_SRC ipython :session nationaldata
national = download_data(Paths.national, Urls.national)
national.head()
#+END_SRC

#+RESULTS:
:      Series ID  Year Period     Label  Value
: 0  LNU04000000  2007    M01  2007 Jan    5.0
: 1  LNU04000000  2007    M02  2007 Feb    4.9
: 2  LNU04000000  2007    M03  2007 Mar    4.5
: 3  LNU04000000  2007    M04  2007 Apr    4.3
: 4  LNU04000000  2007    M05  2007 May    4.3

#+BEGIN_SRC ipython :session nationaldata
national.rename(columns=column_renames, inplace=True)
national.head()
#+END_SRC

#+RESULTS:
:      Series ID  Year Period      date  unemployment_rate
: 0  LNU04000000  2007    M01  2007 Jan                5.0
: 1  LNU04000000  2007    M02  2007 Feb                4.9
: 2  LNU04000000  2007    M03  2007 Mar                4.5
: 3  LNU04000000  2007    M04  2007 Apr                4.3
: 4  LNU04000000  2007    M05  2007 May                4.3

The local data has one fewer month than the national one so I'll remove it here.

#+BEGIN_SRC ipython :session nationaldata
national.tail()
#+END_SRC

#+RESULTS:
:        Series ID  Year Period      date  unemployment_rate
: 118  LNU04000000  2016    M11  2016 Nov                4.4
: 119  LNU04000000  2016    M12  2016 Dec                4.5
: 120  LNU04000000  2017    M01  2017 Jan                5.1
: 121  LNU04000000  2017    M02  2017 Feb                4.9
: 122  LNU04000000  2017    M03  2017 Mar                4.6

#+BEGIN_SRC ipython :session nationaldata
national.drop([122], inplace=True)
national.tail()
#+END_SRC

#+RESULTS:
:        Series ID  Year Period      date  unemployment_rate
: 117  LNU04000000  2016    M10  2016 Oct                4.7
: 118  LNU04000000  2016    M11  2016 Nov                4.4
: 119  LNU04000000  2016    M12  2016 Dec                4.5
: 120  LNU04000000  2017    M01  2017 Jan                5.1
: 121  LNU04000000  2017    M02  2017 Feb                4.9

#+BEGIN_SRC ipython :session nationaldata :results output
peak = national.unemployment_rate.max()
print(peak)
national_peak = numpy.where(national.unemployment_rate==peak)
print(portland.date.iloc[national_peak])
#+END_SRC

#+RESULTS:
: 10.6
: 36    2010 Jan
: Name: date, dtype: object

When did it reach the same level it was at when the recession began?

#+BEGIN_SRC ipython :session nationaldata
national_recession_start = national.unemployment_rate.iloc[recession_start]
post_recession = national[national.Year > 2009]
index = numpy.where(post_recession.unemployment_rate==national_recession_start)[0][0]
post_recession.date.iloc[index]
#+END_SRC

#+RESULTS:
: 2015 Oct

** Plotting

I'm not going to be looking at the numbers so much as comparing plots from now on so I'll remove the grid.

#+BEGIN_SRC ipython :session nationaldata :results none
style = seaborn.axes_style("whitegrid")
style["axes.grid"] = False
seaborn.set_style("whitegrid", style)
#+END_SRC

#+BEGIN_SRC ipython :session nationaldata :file /tmp/national_unemployment.png
figure = pyplot.figure(figsize=(10, 10))
axe = figure.gca()
national.plot(x="date", y="unemployment_rate", ax=axe, legend=False)
portland.plot(x="date", y="unemployment_rate", ax=axe, legend=False)
axe.set_ylabel("% Unemployment")
axe.set_title("Unemployment Rate (Jan 2007 - Feb 2017)")

last = portland.date.count()
axe.text(last, national["unemployment_rate"].iloc[-1], "National")
axe.text(last, portland["unemployment_rate"].iloc[-1], "Portland-Hillsboro-Vancouver")
seaborn.despine()
#+END_SRC

#+RESULTS:
[[file:/tmp/national_unemployment.png]]

* S&P 500

Now I'm going to compare the unemployment rate to the S&P 500 index for the same period. The S&P 500 data came from the [[https://fred.stlouisfed.org/series/SP500/downloaddata][Federal Reserve Bank of St. Louis]]. It contains the S&P 500 monthly index from May 2007 through February 2017.

** Percentage Change From the previous Month

The first data-set is the percent change from the previous month. Although the site let's you set the start date to April 2007 when you actually download the data-set April and May are missing values which are represented as periods ('.') so you have to set the =na_values= argument or the data-frame won't recognize the column as numeric.


#+BEGIN_SRC ipython :session nationaldata
s_and_p = pandas.read_csv("SP500.csv", na_values='.')
s_and_p.head()
#+END_SRC  

#+RESULTS:
:          DATE    VALUE
: 0  2007-04-01      NaN
: 1  2007-05-01      NaN
: 2  2007-06-01  0.22169
: 3  2007-07-01  0.41004
: 4  2007-08-01 -4.34537

#+BEGIN_SRC ipython :session nationaldata :file /tmp/course_4/s_and_p.png
s_and_p.plot(x="DATE", y="VALUE")
#+END_SRC

#+RESULTS:
[[file:/tmp/course_4/s_and_p.png]]

After plotting it I realized that it won't work since that's not what the uneployment data represents. Although you can see the big drop in 2008 - and an unexpected surge shortly thereafter, I think the actual values will be more useful. One problem with comparing the S&P 500 to the unemployment rate is that they are on completely different scales. To be able to plot them I originally downloaded the logarithmic version of the data.

** Natural Log
#+BEGIN_SRC ipython :session nationaldata
s_and_p_ln = pandas.read_csv("SP500_ln.csv", na_values='.')
s_and_p_ln.describe()
#+END_SRC

#+RESULTS:
:             VALUE
: count  118.000000
: mean     7.297456
: std      0.276280
: min      6.629530
: 25%      7.106075
: 50%      7.272825
: 75%      7.571793
: max      7.753580


#+BEGIN_SRC ipython :session nationaldata :file /tmp/course_4/s_and_p_ln.png
figure = pyplot.figure(figsize=(10, 10))
axe = figure.gca()
national.plot(x="date", y="unemployment_rate", ax=axe, legend=False)
portland.plot(x="date", y="unemployment_rate", ax=axe, legend=False)
s_and_p_ln.plot(x="DATE", y="VALUE", ax = axe, legend=False)
axe.set_ylabel("% Unemployment")
axe.set_title("Unemployment Rate April 2007 To February 2017 with ln(S&P 500)")

last = portland.date.count()
axe.text(last, national["unemployment_rate"].iloc[-1], "National")
axe.text(last, portland["unemployment_rate"].iloc[-1], "Portland-Hillsboro-Vancouver")
axe.text(last, s_and_p_ln["VALUE"].iloc[-1], "ln(S&P 500 Index)")
seaborn.despine()
#+END_SRC

#+RESULTS:
[[file:/tmp/course_4/s_and_p_ln.png]]
That was sort of what I wanted, you can see that the S&P 500 Index is dropping rapidly just as the unemployment spikes, then goes on an upward climb as the unmeployment rate goes down. The scale is still off, though, and the housing data is going to be on another scale altogether. I think I'll use the actual index-values and just plot them on separate sub-plotys.

** S and P Index
#+BEGIN_SRC ipython :session nationaldata
s_and_p_index = pandas.read_csv("SP500_index.csv", na_values=".")
s_and_p_index.describe()
#+END_SRC

#+RESULTS:
:              VALUE
: count   118.000000
: mean   1531.959237
: std     409.400311
: min     757.130000
: 25%    1219.360000
: 50%    1440.620000
: 75%    1942.617500
: max    2329.910000

#+BEGIN_SRC ipython :session nationaldata
pre = pandas.DataFrame({"DATE": ["2007-01-01", "2007-02-01", "2007-03-01"], "VALUE": [numpy.nan, numpy.nan, numpy.nan]})
s_and_p_index = pre.append(s_and_p_index)
s_and_p_index["date"] = portland.date.values
s_and_p_index = s_and_p_index.reset_index(drop=True)
s_and_p_index.head()
#+END_SRC

#+RESULTS:
:          DATE    VALUE      date
: 0  2007-01-01      NaN  2007 Jan
: 1  2007-02-01      NaN  2007 Feb
: 2  2007-03-01      NaN  2007 Mar
: 3  2007-04-01      NaN  2007 Apr
: 4  2007-05-01  1511.14  2007 May

#+BEGIN_SRC ipython :session nationaldata
s_and_p_index.tail()
#+END_SRC

#+RESULTS:
:            DATE    VALUE      date
: 117  2016-10-01  2143.02  2016 Oct
: 118  2016-11-01  2164.99  2016 Nov
: 119  2016-12-01  2246.63  2016 Dec
: 120  2017-01-01  2275.12  2017 Jan
: 121  2017-02-01  2329.91  2017 Feb



#+BEGIN_SRC ipython :session nationaldata :results output
s_and_p_nadir = s_and_p_index.VALUE.min()
print(s_and_p_nadir)
s_and_p_nadir = numpy.where(s_and_p_index.VALUE==s_and_p_nadir)[0]
print(s_and_p_index.date.iloc[s_and_p_nadir])
#+END_SRC

#+RESULTS:
: 757.13
: 26    2009 Mar
: Name: date, dtype: object

So the stock-market hit bottom in December of 2008, six months before the Portland-Hillsboro-Vancouver unemployment rate reached its (first) high-point and ten months before the national unemployment rate hit its peak.

Next I'll see if plotting the S&P 500 Index vs Unemployment Rate data shows anything interesting.

#+BEGIN_SRC ipython :session nationaldata :file /tmp/course_4/s_and_p_index.png
figure = pyplot.figure(figsize=(10, 10))
axe = figure.gca()
# the S&P data is missing the first four months so slice
# the unemployment data
axe.plot(s_and_p_index.VALUE, national.unemployment_rate)
axe.plot(s_and_p_index.VALUE, portland.unemployment_rate)
axe.set_title("Unemployment Rate vs S&P 500")
axe.set_xlabel("S&P 500 Index")
axe.set_ylabel("% Unemployment")
last_x = s_and_p_index.VALUE.iloc[-1] + 100
axe.text(last_x, national.unemployment_rate.iloc[-1], "National")
axe.text(last_x, portland.unemployment_rate.iloc[-1], "Portland-Hillsboro-Vancouver")
seaborn.despine()
#+END_SRC

#+RESULTS:
[[file:/tmp/course_4/s_and_p_index.png]]

It looks like as the S&P 500 goes down, the unemployment rate goes up, then, while the unemployment rate is at its peak, the S&P 500 starts to increase, even as the unemployment rate stays high, until around the time when it reached 1200, the unemployment rates began to go down as the stock market improved.

* Purchase Only House Price Index for the United States.
  This data also came from the [[https://fred.stlouisfed.org/series/HPIPONM226S][Federal Reserve Bank of St. Louis]]. It is based on more than six million repeat sales transactions on the same single-family properties. The original source of the data was the [[https://www.fhfa.gov/DataTools/Downloads/Pages/House-Price-Index.aspx][Federal Housing Finance Agency]] (but it only provides an =xls= file, not a =csv=, so I took it from the FED). From the FHFA: 

#+BEGIN_QUOTE
The HPI is a broad measure of the movement of single-family house prices. The HPI is a weighted, repeat-sales index, meaning that it measures average price changes in repeat sales or refinancings on the same properties. This information is obtained by reviewing repeat mortgage transactions on single-family properties whose mortgages have been purchased or securitized by Fannie Mae or Freddie Mac since January 1975.

The HPI serves as a timely, accurate indicator of house price trends at various geographic levels. Because of the breadth of the sample, it provides more information than is available in other house price indexes. It also provides housing economists with an improved analytical tool that is useful for estimating changes in the rates of mortgage defaults, prepayments and housing affordability in specific geographic areas.

The HPI includes house â€‹price figures for the nine Census Bureau divisions, for the 50 states and the District of Columbia, and for Metropolitan Statistical Areas (MSAs) and Divisions.
#+END_QUOTE

#+BEGIN_SRC ipython :session nationaldata
house_price_index = download_data(Paths.house_price, Urls.house_price)
house_price_index.describe()
#+END_SRC

#+RESULTS:
:        HPIPONM226S
: count   121.000000
: mean    204.871983
: std      18.313065
: min     179.220000
: 25%     190.370000
: 50%     202.640000
: 75%     219.900000
: max     244.800000

#+BEGIN_SRC ipython :session nationaldata
house_price_index.head()
#+END_SRC

#+RESULTS:
:          DATE  HPIPONM226S
: 0  2007-02-01       225.36
: 1  2007-03-01       226.52
: 2  2007-04-01       226.50
: 3  2007-05-01       225.40
: 4  2007-06-01       224.61

#+BEGIN_SRC ipython :session nationaldata
house_price_index["price"] = house_price_index.HPIPONM226S
house_price_index["date"] = portland.date[1:].values
house_price_index.head()
#+END_SRC

#+RESULTS:
:          DATE  HPIPONM226S   price      date
: 0  2007-02-01       225.36  225.36  2007 Feb
: 1  2007-03-01       226.52  226.52  2007 Mar
: 2  2007-04-01       226.50  226.50  2007 Apr
: 3  2007-05-01       225.40  225.40  2007 May
: 4  2007-06-01       224.61  224.61  2007 Jun

#+BEGIN_SRC ipython :session nationaldata
pre = pandas.DataFrame({"DATE": ["2007-01-01"], "HPIPONM226S": [numpy.nan], "price": [numpy.nan], "date": ["2007 Jan"]})
house_price_index = pre.append(house_price_index)
house_price_index = house_price_index.reset_index(drop=True)
house_price_index.head()
#+END_SRC

#+RESULTS:
:          DATE  HPIPONM226S      date   price
: 0  2007-01-01          NaN  2007 Jan     NaN
: 1  2007-02-01       225.36  2007 Feb  225.36
: 2  2007-03-01       226.52  2007 Mar  226.52
: 3  2007-04-01       226.50  2007 Apr  226.50
: 4  2007-05-01       225.40  2007 May  225.40

#+BEGIN_SRC ipython :session nationaldata
house_price_index.tail()
#+END_SRC

#+RESULTS:
:            DATE  HPIPONM226S      date   price
: 117  2016-10-01       239.85  2016 Oct  239.85
: 118  2016-11-01       241.53  2016 Nov  241.53
: 119  2016-12-01       242.40  2016 Dec  242.40
: 120  2017-01-01       242.88  2017 Jan  242.88
: 121  2017-02-01       244.80  2017 Feb  244.80

#+BEGIN_SRC ipython :session nationaldata :results output
housing_nadir = house_price_index.price.min()
print(housing_nadir)
housing_nadir = numpy.where(house_price_index.price==housing_nadir)[0]
print(house_price_index.date.iloc[housing_nadir])
#+END_SRC

#+RESULTS:
: 179.22
: 52    2011 May
: Name: date, dtype: object

The House Price Index hit its low point about two and a half years after the stock market hit its low point.


* The Final Plot

#+BEGIN_SRC ipython :session nationaldata :file /tmp/course_4/unemployment_portland_vs_us_2004_2017.png
figure , axes = pyplot.subplots(3,
                                sharex=True)
(sp_axe, housing_axe, unemployment_axe) = axes
figure.set_size_inches(10, 10)

# plot the data
s_and_p_index.plot(x="date", y="VALUE", ax=sp_axe,
                   legend=False)
house_price_index.plot(x="date", y="price", ax=housing_axe,
                       legend=False)

national.plot(x="date", y="unemployment_rate", ax=unemployment_axe,
              legend=False)
portland.plot(x="date", y="unemployment_rate", ax=unemployment_axe,
              legend=False)

# plot the peaks/low-points as vertical lines
peak_color = "darkorange"
# portland-unemployment peaks
for peak in unemployment_peaks:
    for axe in axes:
        axe.axvline(peak, color=peak_color)

points = ((s_and_p_nadir, "crimson"),
          (housing_nadir, "limegreen"),
          (national_peak, "grey"))
          
for point, color in points:
    for axe in axes:
        axe.axvline(point, color=color)

# level at the start of the recession (it was the same for both Portland and the U.S.)
unemployment_axe.axhline(national.unemployment_rate.iloc[recession_start], alpha=0.25)
housing_axe.axhline(
    house_price_index.price.iloc[
        numpy.where(house_price_index.date=="2007 Dec")[0][0]], alpha=0.25)
sp_axe.axhline(
    s_and_p_index.VALUE.iloc[
        numpy.where(s_and_p_index.date=="2007 Dec")[0][0]], alpha=0.25)

# add labels 
unemployment_axe.set_ylabel("% Unemployment")
unemployment_axe.set_xlabel("")

housing_axe.set_ylabel("Sale Price ($1,000)")
sp_axe.set_ylabel("S&P 500 Index")

figure.suptitle("Unemployment Rate April 2007 To February 2017 with S&P 500 Index and House Price Index",
                weight="bold")

# label the data lines
last = portland.date.count()
unemployment_axe.text(last, national.unemployment_rate.iloc[-1], "National")
unemployment_axe.text(last, portland.unemployment_rate.iloc[-1], "Portland-Hillsboro-Vancouver")
sp_axe.text(last, s_and_p_index.VALUE.iloc[-1], "S&P 500")
housing_axe.text(last, house_price_index.price.iloc[-1], "House Price Index")

# color in the recession
sp_axe.axvspan(recession_start, recession_end, alpha=0.25, facecolor='royalblue')
housing_axe.axvspan(recession_start, recession_end, alpha=0.25, facecolor='royalblue')
unemployment_axe.axvspan(recession_start, recession_end, alpha=0.25, facecolor='royalblue')

# label the vertical lines
sp_axe.text(s_and_p_nadir, s_and_p_index.VALUE.max() + 450, "S&P Low", rotation=45)
sp_axe.text(unemployment_peaks[0], s_and_p_index.VALUE.max() + 575,  "Portland High", rotation=45)
sp_axe.text(housing_nadir, s_and_p_index.VALUE.max() + 550, "Housing Low", rotation=45)
sp_axe.text(36, s_and_p_index.VALUE.max() + 450, "U.S. High", rotation=45)
seaborn.despine()

# add a caption
# the coursera sight gives you the option to add a caption via the GUI
figure.text(.1,.000001, """
    Monthly Unadjusted Unemployment Rates for the Portland-Hillsboro-Vancouver area and the entire United States of America compared with the S&P 500 Index and
    House Price Index for the same period. The blue highlighted area is a period of economic contraction (December 2007 through June 2009) defined by the National 
    Bureau of Economic Research. The vertical lines represent (red) the low-point for the S&P 500, (orange) the first peak of the Portland-Hillsboro-Vancouver area 
   unemployment, (gray) the peak of U.S. unemployment (overlaps second Portland-area value matching its first peak), and (green) the low-point for the house-price index.
   The horizontal lines are the values for the metrics at the start of the recession.""")
#+END_SRC

#+RESULTS:
[[file:/tmp/course_4/unemployment_portland_vs_us_2004_2017.png]]

The visualization created was meant to show how Portland, Oregon, United States' unemployment rate related to the national unemployment rate, the stock market, and housing prices. The seasonally unadjusted employment rates for the Portland-Vancouver-Hillsboro area were retrieved from the Bureau of Labor Statistics' web-site, along with the unadjusted unemployment rates for the nation as a whole for the months from January 2017 through February 2017. Hillsboro is an incorporated part of metropolitan Portland and Vancouver is just North of Portland so many of its residents commute to Portland to work, and vice-versa. The monthly S&P 500 Index from May 2007 through February 2017 along with the Purchase Only Price Index from February 2007 through February 2017 were retrieved from the St. Louis Federal Reserve website. The S&P 500 index is the market capitalization of 500 large companies listed on the New York Stock Exchange or NASDAQ. The Purchase Only House Price Index is the average price change in repeat sales or refinancing of the same houses and is maintained by Federal Housing Finance Agency. The beginning and ending of the recession within this time period was taken from the National Bureau of Economic Research (https://www.nber.org/cycles.html). 

The visualization shows that during the recession, beginning in roughly September 2008, Portland's unemployment rate rose faster than the nation as a whole did, but by roughly May 2011 (coinciding with the lowest valuation for the House Price Index) it had dropped slightly lower than the national rate and has stayed in step with it, although it has thus far not followed the uptick in the national rate that began in November of 2016. Additionally the visualization shows the relative timing of the changes in the three metrics. In the year leading up to the recession, unemployment was relatively flat (ignoring the seasonal changes) and the S&P also began relatively flat but then began a downward trend later in the year, the House Price Index, on the other hand, spent most of it starting what would become a four-year decline (since this was during the sub-prime mortgage crisis, this is perhaps not so surprising). The S&P 500 hit its low point during the recession, as might be expected, but the peaks for the unemployment rates occurred when the recession was already over. Also, while the S&P 500 recovered relatively quickly, the unemployment rates for both Portland and the United States as a whole did not reach the level that they were at when the recession began until October 2015.

Truthfulness:

To provide a baseline of trustworthiness I used only government sources (although, of course, some might see that as a negative). 

Beauty:

The internal grid was left out and in its place only vertical and horizontal lines for key values were highlighted (the vertical line represent the worst points for each metric, the horizontal lines the values that the metrics held when the recession began - so the point at which the horizontal line intersects the line after the recession is its recovery point) in an attempt to increase the data-ink ratio.

Functionality:

The data was plotted with a shared x-axis and three separate y-axes so that the states of each could be compared at the same point in time without distorting the plots due to the differing scales for each metric. I didn't include 0 on the y-axes, but the point was to observe inflection points and trends rather than measure exact values so I felt that this was unnecessary (it added a lot of whitespace without actually changing the shapes). As mentioned in the previous section, key points in the data were highlighted (including the time of the recession) so that the viewer could have some additional background information with regard to what was happening, and not just wonder what the strange spike in unemployment was about (or needing to know all the dates ahead of time).

Insightfulness:

By comparing the Portland unemployment rates to the national rates it hopefully revealed the story of how Portland did with regards to the rest of the country - initially doing worse than the nation, then catching up, and currently doing a little better. Additionally, by adding the context of the recession, as well as the performance of the S&P 500 index and the House Price Index during the same period, I hoped to show how unemployment (at least in this time period) moved in relation to other parts of the economy.

* Sources
**  U.S. Federal Housing Finance Agency, Purchase Only House Price Index for the United States [HPIPONM226S], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/HPIPONM226S, April 29, 2017.
