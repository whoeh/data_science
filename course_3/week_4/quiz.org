* Question 1
  Which of the following is an example of clustering?
  - [ ] Accumulate data into groups based on labels
  - [ ] Creating a new representation of the data with fewer features
  - [ ] Compress elongated clouds of data into more spherical representations
  - [X] Separate the data into distinct groups by similarity
* Question 2
  Which of the following are advantages to using decision trees over other models?
  - [ ] Decision trees can learn complex statistical models over a variety of kernel functions
  - [X] Trees often require less preprocessing of data
  - [ ] Trees are naturally resistant to overfitting
  - [X] Trees are easy to interpret and visualize
* Question 3
  What is the main reason that each tree of a random forest only looks at a random subset of the features when building each node?
  - [ ] To learn which features are not strong predictors
  - [X] To improve generalization by reducing correlation among the trees and making the model more robust to bias
  - [ ] To increase interpretability of the model
  - [ ] To reduce the computational complexity associated with training each of the trees needed for the random forest
* Question 4
  Which of the following supervised machine learning methods are greatly affected by feature scaling?
  - [X] Support Vector Machines
  - [ ] Decision Trees
  - [X] Neural networks
  - [ ] Naive Bayes
  - [X] KNN
* Question 5
  Select which of the following statements are true.
  - [ ] For having an audience interpret the fitted model, a support vector machine would be a better choice than a decision tree
  - [ ] For a fitted model that doesn't take up a lot of memory, KNN would be a better choice than logistic regression
  - [X] For predicting future sales of a clothing line, Linear Regression would be a better choice than a decision tree regressor
  - [X] For a model that won't overfit a training set, Naive Bayes would be a better choice than a decision tree
* Question 6
  Match each of the prediction probabilities decision boundaries visualized with the model that created them.
  Image one has fuzzy boundarieds, image two is distinct with irregular edges, image three uses straight lines for edges
  - [X] Neural Network, KNN (k=1), Decision Tree
  - [ ] KNN (k=1), Decision Tree, Neural Network
  - [ ] KNN (k=1), Neural Network, Decision Tree
  - [ ] Neural Network, Decision Tree, KNN (k=1)
* Question 7 (wrong)
  A decision tree of depth 2 is visualized below. Using the =value= attribute of each leaf, find the accuracy score for the tree of depth 2 and the accuracy score for a tree of depth 1. What is the improvement in accuracy between the model of depth 1 and the model of depth 2.

values = [3916, 4108]
True /                                            \ False
value = [3796, 800]                          value = [120, 3408]
/                   \                           /                  \
value = [3760, 288] value = 36, 512          value = 48, 3408  value = 72, 0

Guess: 0.01
* Question 8
  For the autograded assignment in this module, you will create a classifier to predict whether a given blight ticket will be paid on time. Which of the following features should be removed from the training set to prevent data-leakage

  - [ ] agency_name - Agency that issude the ticket
  - [ ] ticket_issued_date - Date and time the ticket was issued
  - [X] collection_status - Flag for payments in collections
  - [ ] graffiti_status - Flag for graffiti violations
  - [X] compliance_detail: More information for why each ticket was marked compliant or non-compliant
* Question 9
  Which of the following might be good ways to help prevent a data leakage situation?
  
  - [X] If time is a factor, remove any data related to the event of interest that doesn't take place prior to the event
  - [ ] Ensure that data is preprocessed outside of the any cross-validation folds
  - [X] Remove variable that a model in production wouldn't have access to
  - [X] Sanity check the model with an unseen validation set
* Question 10
  Given the neural network below, find the correct outputs for the given values of x1 and x2.

  | x1 | x2 | output |
  |----+----+--------|
  |  0 |  0 |      0 |
  |  0 |  1 |      1 |
  |  1 |  0 |      1 |
  |  1 |  1 |      0 |

